{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kili Tutorial: Import OCR pre-annotations in Kili\n",
    "\n",
    "In this tutorial we will see how to import OCR pre-annotations in Kili using [Google vision API](https://cloud.google.com/vision/docs/ocr). Pre-annotating your data will allow you to gain a significant time when performing [OCR](https://cloud.kili-technology.com/docs/text-pdf-interfaces/image-transcription-ocr/#docsNav) using Kili. \n",
    "\n",
    "The data we use comes from [The Street View Text Dataset](http://www.iapr-tc11.org/mediawiki/index.php?title=The_Street_View_Text_Dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading an image from The Street View Dataset in Kili\n",
    "\n",
    "You can obtain the image for this tutorial using the following link (https://drive.google.com/uc?export=view&id=1ceNwCgLwIyyjPwU42xIoz6mMT3enLewW):\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1ceNwCgLwIyyjPwU42xIoz6mMT3enLewW\" width=\"800\">\n",
    "\n",
    "We will use the Google to perform an optical caracter recognition of the different texts in the image.\n",
    "\n",
    "We can now create the interface we will be using in our project. For OCR, the interface to use is a classification jobs with nested transcriptions for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_interface =  {\n",
    "    \"jobs\": {\n",
    "        \"JOB_0\": {\n",
    "            \"mlTask\": \"OBJECT_DETECTION\",\n",
    "            \"tools\": [\n",
    "                \"rectangle\"\n",
    "            ],\n",
    "            \"instruction\": \"Categories\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": False,\n",
    "            \"content\": {\n",
    "                \"categories\": {\n",
    "                    \"STORE_INFORMATIONS\": {\n",
    "                        \"name\": \"Store informations\",\n",
    "                        \"children\": [\n",
    "                            \"JOB_1\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"PRODUCTS\": {\n",
    "                        \"name\": \"Products\",\n",
    "                        \"children\": [\n",
    "                            \"JOB_2\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"input\": \"radio\"\n",
    "            }\n",
    "        },\n",
    "        \"JOB_1\": {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"instruction\": \"Transcription of store informations\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": True\n",
    "        },\n",
    "        \"JOB_2\": {\n",
    "            \"mlTask\": \"TRANSCRIPTION\",\n",
    "            \"instruction\": \"Transcription of products\",\n",
    "            \"required\": 1,\n",
    "            \"isChild\": True\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-vision\n",
      "  Downloading google_cloud_vision-2.6.2-py2.py3-none-any.whl (370 kB)\n",
      "\u001b[K     |████████████████████████████████| 370 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-api-core[grpc]<3.0.0dev,>=1.28.0\n",
      "  Downloading google_api_core-2.3.0-py2.py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting proto-plus>=1.15.0\n",
      "  Downloading proto_plus-1.19.8-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.3.0 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (58.0.4)\n",
      "Collecting google-auth<3.0dev,>=1.25.0\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 10.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.54.0-py2.py3-none-any.whl (207 kB)\n",
      "\u001b[K     |████████████████████████████████| 207 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (2.26.0)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2\n",
      "  Downloading grpcio_status-1.42.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2\n",
      "  Downloading grpcio-1.42.0-cp38-cp38-macosx_10_10_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 23.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (1.16.0)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/envs/kili/lib/python3.8/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.28.0->google-cloud-vision) (1.26.7)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, protobuf, cachetools, grpcio, googleapis-common-protos, google-auth, grpcio-status, google-api-core, proto-plus, google-cloud-vision\n",
      "Successfully installed cachetools-4.2.4 google-api-core-2.3.0 google-auth-2.3.3 google-cloud-vision-2.6.2 googleapis-common-protos-1.54.0 grpcio-1.42.0 grpcio-status-1.42.0 proto-plus-1.19.8 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.8\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-vision\n",
    "import os\n",
    "import io\n",
    "\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from kili.client import Kili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ckwxngdqd007lal9kfj3ae1rg',\n",
       " 'jsonInterface': {'jobs': {'JOB_0': {'mlTask': 'OBJECT_DETECTION',\n",
       "    'tools': ['rectangle'],\n",
       "    'instruction': 'Categories',\n",
       "    'required': 1,\n",
       "    'isChild': False,\n",
       "    'content': {'categories': {'STORE_INFORMATIONS': {'name': 'Store informations',\n",
       "       'children': ['JOB_1']},\n",
       "      'PRODUCTS': {'name': 'Products', 'children': ['JOB_2']}},\n",
       "     'input': 'radio'}},\n",
       "   'JOB_1': {'mlTask': 'TRANSCRIPTION',\n",
       "    'instruction': 'Transcription of store informations',\n",
       "    'required': 1,\n",
       "    'isChild': True},\n",
       "   'JOB_2': {'mlTask': 'TRANSCRIPTION',\n",
       "    'instruction': 'Transcription of products',\n",
       "    'required': 1,\n",
       "    'isChild': True}}},\n",
       " 'title': 'Street text annotation',\n",
       " 'roles': [{'user': {'id': 'user-6',\n",
       "    'email': 'test+github@kili-technology.com'},\n",
       "   'role': 'ADMIN'}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Authenticate to Kili Technology\n",
    "api_key = os.getenv('KILI_USER_API_KEY')\n",
    "api_endpoint = os.getenv('KILI_API_ENDPOINT')\n",
    "kili = Kili(api_key=api_key, api_endpoint=api_endpoint)\n",
    "\n",
    "# Create an OCR project\n",
    "project = kili.create_project(\n",
    "    description='OCR street view',\n",
    "    input_type='IMAGE',\n",
    "    json_interface=json_interface,\n",
    "    title='Street text annotation'\n",
    ")\n",
    "project_id = project['id']\n",
    "users = kili.users(api_key=api_key, fields=['email'])\n",
    "kili.append_to_roles(\n",
    "    project_id=project_id,\n",
    "    user_email=users[0]['email'],\n",
    "    role='ADMIN'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating OCR annotations using Google Vision API\n",
    "\n",
    "We will now see how to perform OCR on our image using Google Vision API.\n",
    "\n",
    "First you will need to create an account on https://cloud.google.com:\n",
    "  - create a project (or use an exesting one)\n",
    "  - then go to  \"API and services\"/library and serach for \"vision API\"\n",
    "  - activate the API for your project (You might need to associate facturation information if you haven't already)\n",
    "  \n",
    "Now that the API is activated we will need to get an API in order to call later in our project:\n",
    "  - go to \"API and services\"/indentification\n",
    "  - create a service account with authorization to use the vision API\n",
    "  \n",
    "On the service account details page:\n",
    "  - click on add a key\n",
    "  - download the key using json format\n",
    "  - place the key in the folder of the project\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Google Cloud API using: `pip install --upgrade google-cloud-storage`\n",
    "\n",
    "We can now start to code to add OCR annotations to the asset metadata! (You can also perform OCR on remote images using a URL: [detect text in images](https://cloud.google.com/vision/docs/ocr#vision_text_detection-python))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the path to your API_KEY\n",
    "PATH_API_KEY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit():\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # If you don't specify credentials when constructing the client, the\n",
    "    # client library will look for credentials in the environment.\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    credentials = service_account.Credentials.from_service_account_file(PATH_API_KEY)\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    text_annotations = []\n",
    "\n",
    "    for text in texts:\n",
    "        \n",
    "        vertices = [{\"x\": vertex.x, \"y\": vertex.y}\n",
    "                    for vertex in text.bounding_poly.vertices]\n",
    "        \n",
    "        tmp = {\"description\": text.description,\n",
    "               \"boundingPoly\": {\n",
    "                      \"vertices\": vertices,\n",
    "                  },\n",
    "              }\n",
    "        \n",
    "        text_annotations.append(tmp)\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "                \n",
    "    return text_annotations  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "text_annotations = detect_text(PATH_TO_IMG) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to format the results of the OCR to fit in Kili's asset metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_WIDTH = 1680\n",
    "IMG_HEIGHT = 1050\n",
    "\n",
    "full_text_annotations = {\n",
    "    \"fullTextAnnotation\": {\n",
    "        \"pages\": [{\"height\": IMG_HEIGHT, \"width\": IMG_WIDTH}],}, \"textAnnotations\": text_annotations\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We respect Google's Vision API [`AnnotateImageResponse`](https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse) format. So in the end, the OCR data to insert into Kili as a JSON metadata contains:\n",
    "\n",
    "- [Full text annotation](https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse#TextAnnotation). A list of pages in the document with their respective heights and widths.\n",
    "- [A list of text annotations](https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageResponse#EntityAnnotation) with:\n",
    "  - the text content;\n",
    "  - coordinates of the bounding box.\n",
    "\n",
    "```\n",
    "{\n",
    "  \"fullTextAnnotation\": { \"pages\": [{ \"height\": 914, \"width\": 813 }] },\n",
    "  \"textAnnotations\": [\n",
    "    {\n",
    "      \"description\": \"7SB75\",\n",
    "      \"boundingPoly\": {\n",
    "        \"vertices\": [\n",
    "          { \"x\": 536, \"y\": 259 },\n",
    "          { \"x\": 529, \"y\": 514 },\n",
    "          { \"x\": 449, \"y\": 512 },\n",
    "          { \"x\": 456, \"y\": 257 }\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"description\": \"09TGG\",\n",
    "      \"boundingPoly\": {\n",
    "        \"vertices\": [\n",
    "          { \"x\": 436, \"y\": 256 },\n",
    "          { \"x\": 435, \"y\": 515 },\n",
    "          { \"x\": 360, \"y\": 515 },\n",
    "          { \"x\": 361, \"y\": 256 }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'ckhc6pwtr020v0785m7adiare'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add asset with pre-annotations to project\n",
    "\n",
    "external_id = 'store'\n",
    "content = 'https://drive.google.com/uc?export=view&id=1ceNwCgLwIyyjPwU42xIoz6mMT3enLewW'\n",
    "\n",
    "kili.append_many_to_dataset(\n",
    "    project_id=project_id,\n",
    "    content_array=[content],\n",
    "    external_id_array=[external_id],\n",
    "    json_metadata_array=[full_text_annotations]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate in Kili\n",
    "\n",
    "You can now annotate your images and you will se the text automatically extracted.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/kili-technology/kili-playground/master/recipes/img/store_with_ocr.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
